{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning \n",
    "**üôãüèª‚Äç‚ôÇÔ∏èQ:** Was ist Machine Learning (ML)?\n",
    "\n",
    "**üí°A:** ML ist die algorithmische Erstellung eines statistischen Models auf der Grundlage eines Datensatzes.\n",
    "\n",
    "\n",
    "## Mathe üìñ\n",
    " Bevor wir beginnen, ein bisschen mathemathische Notation:\n",
    "- **x**: (Feature) Vector\n",
    "\n",
    "- $y$: Label\n",
    "\n",
    "- $N$: Gr√∂√üe des Datasets \n",
    "\n",
    "- $X$: Dataset \n",
    "> üìù Gibt es zu jedem Feature Vector ein Label, so setzt sich das Dataset aus $X$ = {**x**<sub>$i$</sub>$, y$<sub>$i$</sub>)}$_{i=1}^N$ zusammen. Sind die Daten unlabeled, gilt $X$ = {**x**<sub>$i$</sub>)}$_{i=1}^N$\n",
    "\n",
    "\n",
    "## Unterscheidung von ML-Algorithmen üîé\n",
    "ML-Algorithmen werden allgmein nach ihren \"Lerntypen\" klassifiziert. \n",
    "\n",
    "### Supervised Learning\n",
    "Das Ziel eines Supervised Learning Algorithmus ist es, aus einem Dataset ein Model zu erstellen, das einen Feature Vectors **x** als Eingabe nimmt und Informationen ausgibt, die es erlauben, das Label f√ºr diesen Vektor abzuleiten/zu bestimmen. Die Anwendung von Supervised Learning Algorithmen ist vielf√§ltig, von Klassifikationsproblemen (z.B. automatische Spam Erkennung o. Bildklassifizierung) bis hin zu Prognoseproblemen (z.B. Kusentwicklungen o. Krankheitsprognosen).\n",
    "\n",
    "### Semi-Supervised Learning\n",
    "Beim Semi-Supervised Learning enth√§lt das Dataset sowohl labeld als auch unlabeld Feature Vectors. Dabei ist das Ziel, das gleiche wie bei einem Supervised Learning Algorithmus. Die Hoffnung ist hier, dass die Verwendung vieler unlabeld Feature Vectors\n",
    "dem Lernalgorithmus dabei helfen, ein generischeres Model zu finden.\n",
    "\n",
    "### Unsupervised Learning\n",
    "Beim Unsupervised Learning ist das Dataset eine Sammlung von unlabeld Feature Vectors. Das Ziel eines Unsupervised Learning Algorithmus ist\n",
    "ein Model zu erstellen, dass einen Vektor **x** als Eingabe nimmt und ihn entweder in einen anderen Vektor oder in einen Wert umwandelt, der zur L√∂sung eines praktischen Problems verwendet werden kann. M√∂gliche Anwendungsgebiete sind clustering, Dimensionsreduktion oder Ausrei√üer-Erkennung.\n",
    "\n",
    "### Reinforcement Learning\n",
    "Ein weiterer \"Lerntyp\" ist das Reinforcement Learning. √Ñhnlich zum Unsupervised Learning werden keine Label im Datasets ben√∂tigt. Vielmehr geht es darum, auf Basis von Belohnungen eine optimale Strategie in seinem aktuellen Umweld zu entwickeln. Das Reinforcement Learning behandelt meistens  Probleme, bei welchen sequenzielle Entscheidungen getroffen werden m√ºssen (z.B. Schach spielen). \n",
    "\n",
    "**üìπVideo-Linküìπ**:\n",
    "[MIT - Introduction to Machine Learning](https://www.youtube.com/watch?v=h0e2HAPTGF4)\n",
    "\n",
    "\n",
    "## Wie funktioniert Machine Learning? ü§ñ\n",
    "### Dataset\n",
    "Ein Machine Learning Problem startet immer mit dem Dataset selbst. Zwei wichtige Eigenschaften eines Datasets sind dabei die **Qualit√§t** und die **Gr√∂√üe**.\n",
    "\n",
    "#### Gr√∂√üe\n",
    "> üìù üëäFaustregelüëä: Ein Dataset sollte immer ein Vielfaches der lernbaren Labels/Paramenter als Gr√∂√üe haben. Zu gro√ü gibt es eigentlich nicht.\n",
    "\n",
    "Hier ein paar Beispiele von bekannten Datasets:\n",
    "\n",
    "| Dataset | Labels | Gr√∂√üe |\n",
    "| :-- | --: | --: |\n",
    "| [Iris Data Set](https://archive.ics.uci.edu/ml/datasets/iris) | 3 | 150 |\n",
    "| [Chest X-Ray Images](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia) | 2 | 5.863 |\n",
    "| [CIFAR-10](https://www.tensorflow.org/datasets/catalog/cifar10) | 10 | 6.000 |\n",
    "| [MNIST](https://www.tensorflow.org/datasets/catalog/mnist) | 10 | 70.000 |\n",
    "| [ImageNet](https://image-net.org/)| 21.800 | 14.200.00 |\n",
    "\n",
    "#### Qualit√§t\n",
    "**üôãüèª‚Äç‚ôÇÔ∏èQ:** Was versteht man unter der Qualit√§t eines Datasets?\n",
    "\n",
    "**üí°A:** Die Qualit√§t eines Datasets misst, wie gut die Daten die beabsichtigte Aufgabe erf√ºllen.\n",
    "\n",
    "Um die Qualit√§t eines Datasets herrauszufinden, k√∂nnen diese Fragen helfen:\n",
    "* Sind die Daten repr√§sentativ?\n",
    "* Wie h√§ufig sind Fehler? (z.B. fehlende Features o. falsche Label)\n",
    "* Wie genau sind die Daten? \n",
    "* Sollten/k√∂nnen Werte transformiert werden?\n",
    "\n",
    "### ML-Algorithmus\n",
    "Damit aus dem Dataset ein Model generiert werden kann, wird ein ML-Algorithmus genutzt. Ein kleiner √úberblick √ºber die weitverbreitetsten ML-Algorithmen:\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Support Vector Machine (SVM)\n",
    "* K- Nearest Neighbors (KNN)\n",
    "* Self-Organizing Map (SOM)\n",
    "* K-Means\n",
    "* Gradient Boosting\n",
    "* Convolutional Neural Network (CNN)\n",
    "* Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Je nach Problemstellung und Dataset wird k√∂nnen ein oder mehrere ML-Algorithmen genutzt werden um ein Model zu trainieren.\n",
    "\n",
    "### Model\n",
    "**üôãüèª‚Äç‚ôÇÔ∏èQ:** Was ist ein Model?\n",
    "\n",
    "**üí°A:** Ein Model ist eine aus Daten abgeleitete mathematische Beziehung, die ein ML-System verwendet, um Vorhersagen zu treffen.\n",
    "\n",
    "> üìù Dataset + ML-Algorithmus = Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Beispiel 1 üå≥Decision Treeüå≥\n",
    "### Dataset\n",
    "Als erstes Beispiel gucken wir uns das [Iris Data Set](https://archive.ics.uci.edu/ml/datasets/iris) an. Das Dataset enth√§lt Informationen zu drei Klassen der Iris-Pflanze, n√§mlich Setosa, Versicolour und Virginica, mit den folgenden Attributen: Blattl√§nge, Battbreite, Bl√ºtenblattl√§nge und Bl√ºtenblattbreite.\n",
    "\n",
    "> üìù F√ºr Data Analysis ‚ûî [pandas](https://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "#Laden des Iris Dataset\n",
    "iris_data = load_iris(as_frame=True)\n",
    "\n",
    "# Konvertierung der CSV in Pandas Dataframe\n",
    "df = pd.DataFrame(data=iris_data.frame)\n",
    "\n",
    "# Zusammenfassung des Datasets\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualisierung \n",
    "fig, ax = plt.subplots()\n",
    "# Scatterplot\n",
    "colors = ['tab:red','tab:blue','tab:orange']\n",
    "scatter = ax.scatter(df['petal length (cm)'], df['petal width (cm)'], c=df['target'], cmap=matplotlib.colors.ListedColormap(colors))\n",
    "# Legende\n",
    "legend1 = ax.legend(scatter.legend_elements()[0], iris_data.target_names, title='Typ')\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ML-Algorithmus\n",
    "Ein **Decision Tree** ist ein azyklischer Graph, der zur Entscheidungsfindung verwendet werden kann. In jeder Node des Graphen wird ein bestimmtes Feature $j$ des Feature Vectors **x** untersucht. Wenn der Wert von **x**$^j$ unter einem bestimmten Schwellenwert liegt, wird dem linken Branch gefolgt, andernfalls wird dem rechte Branch gefolgt.\n",
    "\n",
    "**Decision Trees** k√∂nnen auf Basis unterschiedlicher Lernalgorithmen trainiert werden. In diesem Beispiel nutzen wir die [Scikit-learn Libary](https://scikit-learn.org/stable/modules/tree.html), welche **CART** verwendet.\n",
    "\n",
    "Der Parameter `criterion` ist ein sogenannter **Hyperparameter**.\n",
    "> üìù Hyperparameter sind Parameter, deren Werte *nicht* durch Training erlernt werden. Sie dienen zur Kontrolle des Lernverhaltens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Unterteilen des Dataset in Trainings- & Testdaten (70:30)\n",
    "X, y = iris_data.data, iris_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# Berechnen des Models\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model\n",
    "Mit `tree.plot()` kann der resultierende Decision Tree vizualisiert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "# Visualisierung des Models\n",
    "tree.plot_tree(clf, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prediction der Label von ungesehenen Testdaten\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Genauigkeit der Testdaten-Klassifikation:', round(accuracy_score(y_test, y_pred),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## üß†CNNüß†\n",
    "### Dataset\n",
    "Als n√§chstes Beispiel gucken wir uns das [MNIST](https://www.tensorflow.org/datasets/catalog/mnist) an. Das Dataset enth√§lt Bilder (28x28 Pixel) mit handgeschriebenen Ziffern (0-9).\n",
    "\n",
    "Bevor das NN trainiert wird, werden die Daten in einem Vorverarbeitungsschritt bearbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Laden des MNIST Dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Beschreibung des Test-Dataset\n",
    "print('Gr√∂√üe & Dimensionen des Test-Dataset:', X_train.shape)\n",
    "\n",
    "\n",
    "'''Trainings Dataset'''\n",
    "#Reshape (60000 28, 28) -> (60000, 28 * 28) & Skalierung von [0,255] -> [0,1]\n",
    "X_train = X_train.reshape((60000, 28 * 28))\n",
    "X_train = X_train.astype('float32') / 255\n",
    "\n",
    "'''Test Dataset'''\n",
    "#Reshape & Skalierung\n",
    "X_test = X_test.reshape((10000, 28 * 28))\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####  MNIST-Beispiel Ziffern\n",
    "<img src=\"https://i.imgur.com/OGQ1Ybc.png\" width=500 height=500 />\n",
    "\n",
    "### ML-Algorithmus\n",
    "Ein **Neural Network** (NN) basiert auf einer Sammlung von miteinander verbundenen Nodes, die als Neuronen/Neurons bezeichnet werden. Jede Verbindung kann ein Signal an andere Neurons √ºbertragen. Um das Output-Signal eines Neurons zu berechnen wird die **gewichtete** Summe aller Input-Signal genommen und ein **Bias** addiert. Diese gewichtete Summe wird dann durch eine (in der Regel nichtlineare) Aktivierungsfunktion geleitet, um das Output-Signal zu berrechnen.\n",
    "\n",
    "Die Neurons des NNs befinden sich in den jeweiligen Layern des Netzwerkes. In diesem Beispiel besteht das Netzwerk aus einem `Flatten` Layer und zwei `Dense` (auch *fully connected* genannt) Layern. Im letzten Layer (auch *Output Layer*) befinden sich 10 Nerons. Durch die `softmax`-Aktivierungsfunktion gibt dieses Layer 10 Wahrscheinlichkeiten, korrespondierend zu den 10 m√∂glichen Ziffern, zur√ºck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Erstellen der Netzwerkstruktur\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Kompilieren des Netzwerkes\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nach dem Kompilieren des NNs kann dieses mit `fit()` trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Trainieren des NNs\n",
    "network.fit(X_train, y_train, epochs=8, batch_size=128)\n",
    "\n",
    "# Evaluieren des NNs\n",
    "test_loss, test_acc = network.evaluate(X_test, y_test)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vergleicht man die beiden `accuracy`s, so stellt man fest, dass die des Training h√∂her ist als die des Tests. Dies ist ein Beispeil von **Overfitting**.\n",
    "\n",
    "> üìù Overfitting ist das √úberoptimieren des Models anhand der Trainingsdaten. Es werden Repr√§sentationen gelernt, die spezifisch f√ºr die Trainingsdaten sind und keine generalisierten Representationen f√ºr Daten au√üerhalb des Trainings Datasets.\n",
    "\n",
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(network.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Quellen / Literatur\n",
    "\n",
    "- Fran√ßois Chollet (2017): Deep Learning with Python - Manning Publications\n",
    "- Andriy Burkov (2019): The Hundred-Page Machine Learning Book \n",
    "- [Google Machine Learning Education](https://developers.google.com/machine-learning)\n",
    "- [scikit-learn](https://scikit-learn.org/stable/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}